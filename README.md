# DataPulse - Система прогнозирования продаж на основе анализа данных

## Общее описание программы

DataPulse представляет собой современное десктопное приложение для прогнозирования продаж, построенное на базе машинного обучения и передовых методов анализа временных рядов. Это комплексное решение, которое сочетает в себе мощный аналитический движок с интуитивно понятным графическим интерфейсом, разработанным с использованием библиотеки Tkinter.

Программа предназначена для бизнес-аналитиков, менеджеров по продажам и владельцев бизнеса, которым необходимо строить точные прогнозы продаж на основе исторических данных. Система автоматически обрабатывает входные данные, создает сложные признаки, обучает модели машинного обучения и генерирует детализированные отчеты в формате PDF.

## Архитектура и принципы работы

### Модульная структура

Приложение построено по модульному принципу, где каждый компонент отвечает за определенную функциональность:

**config.py** - централизованная конфигурация приложения, содержащая все настройки: форматы данных, параметры моделей машинного обучения, цветовые схемы интерфейса, шрифты и требования к данным. Использует классы AppConfig и DataValidationRules для обеспечения согласованности настроек во всей системе.

**data_manager.py** - интеллектуальный менеджер данных, который включает класс DataManager для обработки CSV-файлов и AdvancedFeatureEngineer для создания расширенных признаков. Этот модуль обеспечивает загрузку, валидацию, очистку и преобразование сырых данных в формат, пригодный для машинного обучения.

**logging_config.py** - система логирования с ротацией файлов, которая обеспечивает отслеживание работы приложения, диагностику ошибок и аудит операций. Использует RotatingFileHandler для предотвращения переполнения дискового пространства.

**main.py** - основной модуль приложения, содержащий графический интерфейс на Tkinter. Реализует класс SalesForecastApp с современным дизайном, вкладками для различных аспектов анализа и интерактивными визуализациями на matplotlib.

**ml_engine.py** - продвинутый движок машинного обучения, включающий ForecastEngine для обучения и прогнозирования, ModelFactory для создания моделей, HyperparameterOptimizer для тонкой настройки параметров и TimeSeriesValidator для кросс-валидации временных рядов.

**report_generator.py** - мощная система генерации отчетов, создающая профессиональные PDF-документы с использованием Jinja2 для шаблонов и WeasyPrint для рендеринга. Включает графики matplotlib, статистические сводки и детализированные таблицы.

### Взаимодействие модулей

Модули взаимодействуют через четко определенные интерфейсы и обмен данными в формате сессий. Процесс начинается с загрузки данных через DataManager, который передает обработанные данные главному приложению. При запуске прогнозирования main.py вызывает ml_engine для обучения модели, которая возвращает результаты прогноза. При генерации отчетов report_generator использует данные из сессии для создания PDF-документов. Все модули используют единую систему конфигурации и логирования для обеспечения согласованности.

## Методы машинного обучения

# Детальное описание методов машинного обучения в DataPulse

## Алгоритмы и подходы

### Random Forest (Случайный лес) - Основной алгоритм

DataPulse использует **Random Forest Regressor** в качестве основного алгоритма прогнозирования, что обусловлено несколькими ключевыми преимуществами для задач прогнозирования временных рядов:

**Архитектура ансамбля**: Алгоритм строет множество деревьев решений (100 деревьев в базовой конфигурации), где каждое дерево обучается на случайной подвыборке данных (bootstrap sampling) и случайном подмножестве признаков. Это создает разнообразие в ансамбле, что значительно снижает variance и предотвращает переобучение.

**Параметры модели**:
- `n_estimators=100` - оптимальный баланс между производительностью и точностью
- `max_depth=10` - ограничение глубины деревьев для регуляризации
- `min_samples_split=2` - минимальное количество samples для разделения узла
- `min_samples_leaf=1` - минимальное количество samples в листьях
- `random_state=42` - воспроизводимость результатов

**Механизм работы**: Каждое дерево в лесе независимо обучается на случайных подмножествах данных и признаков. При прогнозировании для нового наблюдения каждое дерево дает свой прогноз, а финальный результат вычисляется как среднее значение всех индивидуальных прогнозов.

**Преимущества для временных рядов**:
- Устойчивость к шуму и выбросам в данных о продажах
- Способность улавливать сложные нелинейные зависимости
- Автоматическое определение важности признаков
- Нет требований к нормализации данных

## Feature Engineering (Создание признаков)

### Расширенная инженерия временных признаков

Класс `AdvancedFeatureEngineer` создает комплексные признаки из временных меток:

**Базовые временные компоненты**:
- `day_of_week` (0-6) - день недели как категориальная переменная
- `month` (1-12) - месяц года
- `year` - год для учета долгосрочных трендов
- `quarter` (1-4) - квартал года
- `day_of_year` (1-365) - порядковый день в году

**Календарные флаги**:
- `is_month_start`, `is_month_end` - флаги начала/конца месяца
- `is_quarter_start`, `is_quarter_end` - флаги начала/конца квартала
- `is_weekend` - бинарный признак выходных дней

### Циклическое кодирование временных признаков

Для учета циклической природы временных данных применяется синус-косинусное преобразование:

**Месяцы**:
```python
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
```

**Дни недели**:
```python
df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
```

**Дни года**:
```python
df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)
df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)
```

Это преобразование позволяет модели корректно интерпретировать циклические паттерны, где декабрь (12) и январь (1) являются соседними значениями.

### Доменные признаки для российского рынка

**Праздничный календарь**:
Система включает распознавание российских государственных праздников:
- Новогодние каникулы (1-8 января)
- День защитника Отечества (23 февраля)
- Международный женский день (8 марта)
- День весны и труда (1 мая)
- День Победы (9 мая)
- День России (12 июня)
- День народного единства (4 ноября)

**Контекстные признаки**:
- `is_holiday` - прямой признак праздничного дня
- `is_pre_holiday` - день перед праздником
- `is_post_holiday` - день после праздника

### Статистические и лаговые признаки

**Лаговые значения**:
Система создает лаги различных порядков для учета автокорреляции:
- Краткосрочные лаги: 1, 2, 3 дня
- Среднесрочные лаги: 7 дней (недельная сезонность)
- Долгосрочные лаги: 14, 30 дней

**Скользящие статистики**:
Для окон 7, 14 и 30 дней вычисляются:
- `rolling_mean` - скользящее среднее
- `rolling_std` - скользящее стандартное отклонение
- `rolling_min`, `rolling_max` - экстремальные значения
- `ratio_to_rolling_mean` - отношение текущего значения к скользящему среднему

**Производные метрики**:
- `sales_trend_7`, `sales_trend_30` - темпы роста относительно лагов
- `volatility_14` - коэффициент вариации для измерения волатильности

## Валидация и оптимизация

### Временная кросс-валидация

Для корректной оценки моделей временных рядов применяется `TimeSeriesSplit` с специальными настройками:

**Конфигурация валидации**:
- `n_splits=5` - количество фолдов
- `test_size=7` - размер тестового окна (7 дней)
- `gap=0` - отсутствие разрыва между train и test

**Процесс валидации**:
```
Fold 1: Train [0...t1], Test [t1+1...t1+7]
Fold 2: Train [0...t2], Test [t2+1...t2+7]
...
Fold 5: Train [0...t5], Test [t5+1...t5+7]
```

Этот подход предотвращает утечку данных из будущего и обеспечивает реалистичную оценку производительности модели на последовательных временных интервалах.

### Метрики качества

**Основные метрики**:

1. **MAPE (Mean Absolute Percentage Error)**:
   ```python
   mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true == 0, 1, y_true))) * 100
   ```
   - Интерпретируемость в процентах
   - Чувствительность к масштабу данных
   - Идеальна для бизнес-отчетности

2. **MAE (Mean Absolute Error)**:
   ```python
   mae = np.mean(np.abs(y_true - y_pred))
   ```
   - Робастность к выбросам
   - Интерпретация в абсолютных единицах

**Дополнительные метрики**:
- Стандартное отклонение ошибок по фолдам
- Время обучения и прогнозирования
- Важность признаков

### Оптимизация гиперпараметров

**RandomizedSearchCV** для эффективного поиска оптимальных параметров:

**Пространство поиска для Random Forest**:
```python
{
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
```

**Процесс оптимизации**:
1. Случайная выборка 20 комбинаций параметров
2. Оценка каждой комбинации через временную кросс-валидацию
3. Выбор комбинации с наилучшим `neg_mean_absolute_error`

**Критерии остановки**:
- `n_iter=20` - баланс между качеством и временем вычислений
- `cv=5` - количество фолдов кросс-валидации
- `scoring='neg_mean_absolute_error'` - целевая метрика

## Процесс обучения модели

### Подготовка данных для обучения

**Этап 1: Селекция признаков**
```python
feature_columns = [col for col in df_prepared.select_dtypes(include=[np.number]).columns 
                  if col != 'total_sales' and not col.startswith('date')]
```

**Этап 2: Обработка пропусков**
- Forward fill для временных последовательностей
- Backward fill как резервный метод
- Удаление признаков с >50% пропусков

**Этап 3: Разделение данных**
- Сохранение временного порядка
- Тестовая выборка - последние 20% наблюдений
- Стратификация не применяется для сохранения временной структуры

### Обучение модели Random Forest

**Инициализация модели**:
```python
model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=2,
    min_samples_leaf=1,
    random_state=42,
    n_jobs=-1  # параллельные вычисления
)
```

**Процесс обучения**:
1. **Bootstrap sampling**: Создание 100 случайных подвыборок с возвращением
2. **Построение деревьев**: Для каждой подвыборки строится дерево решений
3. **Случайный выбор признаков**: На каждом разделении узла рассматривается √n_features
4. **Рекурсивное разделение**: До достижения критериев остановки

**Критерии остановки роста деревьев**:
- Достижение max_depth
- Минимальное количество samples в узле
- Отсутствие улучшения критерия разделения

### Оценка важности признаков

**Mean Decrease Impurity**:
```python
feature_importance = model.feature_importances_
```
Метод оценивает вклад каждого признака в уменьшение неопределенности (Gini impurity) across всех деревьев.

**Анализ важности**:
- Временные признаки обычно имеют высокую важность
- Лаговые значения выявляют автокорреляцию
- Праздничные признаки важны для пиковых продаж

### Кэширование и воспроизводимость

**Хэширование данных**:
```python
data_hash = hashlib.md5(data_str.encode()).hexdigest()
model_path = f"models/model_{data_hash}.joblib"
```

**Механизм кэширования**:
- Сохранение обученных моделей на диск
- Повторное использование при идентичных данных
- Автоматическая инвалидация при изменении данных

Этот комплексный подход к машинному обучению обеспечивает высокую точность прогнозов, устойчивость к переобучению и прозрачность процесса для конечного пользователя.

## Процесс работы системы

### Загрузка и подготовка данных

Пользователь загружает CSV-файл с обязательными колонками: date (дата), quantity (количество), price (цена). Система автоматически проверяет целостность данных, валидирует диапазоны значений, удаляет дубликаты и пропуски. Затем данные агрегируются по дням и обогащаются расширенными признаками.

### Прогнозирование и визуализация

Обученная модель используется для прогнозирования продаж на 7 дней вперед. Система создает прогнозы с доверительными интервалами (±20%) и отображает их на интерактивных графиках вместе с историческими данными. Пользователь может анализировать тенденции, сезонные patterns и аномалии.

### Генерация отчетов

DataPulse предоставляет три типа отчетов: отчет по историческим данным, отчет по прогнозам и полный отчет. Все отчеты включают профессиональные визуализации, ключевые метрики, детализированные таблицы и информацию о качестве модели.

## Технические особенности

### Производительность и масштабируемость

Система оптимизирована для работы с большими объемами данных через эффективную обработку временных рядов и кэширование обученных моделей. Максимальный размер файла ограничен 50 МБ для обеспечения быстрой обработки.

### Надежность и отказоустойчивость

Комплексная система валидации данных, обработки исключений и логирования обеспечивает стабильную работу приложения. Автоматическое восстановление после ошибок и подробные сообщения пользователю делают систему надежной в эксплуатации.

### Безопасность данных

Все обработки выполняются локально, без передачи данных на внешние серверы. Это обеспечивает конфиденциальность бизнес-информации и соответствует требованиям защиты данных.

## Преимущества системы

DataPulse сочетает в себе мощь современных методов машинного обучения с удобством использования, что делает продвинутую аналитику доступной для пользователей без глубоких знаний в data science. Система адаптирована specifically для российского рынка с учетом местных праздников и бизнес-реалий, обеспечивая высокую точность прогнозов в локальном контексте.

Гибкая архитектура позволяет легко расширять функциональность, добавлять новые алгоритмы машинного обучения и адаптировать систему под специфические потребности бизнеса. Профессиональная генерация отчетов и интуитивный интерфейс делают DataPulse готовым решением для коммерческого использования в различных отраслях розничной торговли и сферы услуг.
